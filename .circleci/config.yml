version: 2.1

workflows:
  version: 2
  run-checks:
    jobs:
      - install
      - linter:
          requires:
            - install
      - cloudsql-tests:
          requires:
            - install
      - api-build
      - api-tests:
          requires:
            - api-build
      - dag-tests:
          requires:
            - install
      - composer-deploy:
          requires:
            - dag-tests
          filters:
            branches:
              only:
                - master


jobs:
  api-build:
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
    working_directory: ~/data-gcp/api
    steps:
      - checkout:
          path: ~/data-gcp
      - restore_cache:
          key: dependencies-{{ checksum "dev-requirements.txt" }}
      - run:
          name: Install Python deps in a venv
          command: |
            python3 -m venv venv
            . venv/bin/activate
            pip install -r dev-requirements.txt
      - save_cache:
          key: dependencies-{{ checksum "dev-requirements.txt" }}
          paths:
            - "venv"
      - persist_to_workspace:
          root: .
          paths:
            - .

  api-tests:
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
      - image: circleci/postgres:12
        environment:
          POSTGRES_PASSWORD: postgres
    working_directory: ~/data-gcp/api
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install psql
          command: sudo apt install postgresql-client
      - run:
          name: Run tests
          command: |
            export PYTHONPATH=$PYTHONPATH:~/data-gcp/api
            . venv/bin/activate
            ./run_tests.sh

  install:
    working_directory: ~/data-gcp
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
    steps:
      - checkout
      # Download and cache dependencies
      - restore_cache:
          keys:
            - data-gcp-{{ checksum "poetry.lock" }}
      - run:
          name: Install dependencies
          command: |
            poetry run pip install --upgrade pip
            poetry install
      - save_cache:
          key: data-gcp-{{ checksum "poetry.lock" }}
          paths:
            - /home/circleci/.cache/pypoetry/virtualenvs

  linter:
    working_directory: ~/data-gcp
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
    steps:
      - checkout
      # Download and cache dependencies
      - restore_cache:
          keys:
            - data-gcp-{{ checksum "poetry.lock" }}
      - run:
          name: Run linter
          command: poetry run black --check .

  dag-tests:
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
    working_directory: ~/data-gcp
    environment:
      - AIRFLOW_HOME=~/data-gcp
      - DAG_FOLDER=~/data-gcp/dags
      - RECOMMENDATION_SQL_USER=test_user
      - RECOMMENDATION_SQL_PASSWORD=test_password
      - RECOMMENDATION_SQL_PUBLIC_PORT=1234
      - RECOMMENDATION_SQL_PUBLIC_IP=11.111.111.111
    steps:
      - checkout
      - restore_cache:
          key: data-gcp-{{ checksum "poetry.lock" }}
      - run:
          name: Run tests
          command: |
            poetry run airflow initdb
            poetry run pytest dags/tests

  cloudsql-tests:
    docker:
      - image: circleci/python:3.7
      - image: circleci/postgres:12
        environment:
          POSTGRES_PASSWORD: postgres
    working_directory: ~/data-gcp
    steps:
      - checkout
      - restore_cache:
          key: data-gcp-{{ checksum "poetry.lock" }}
      - run:
          name: Install psql
          command: sudo apt install postgresql-client
      - run:
          name: Run tests
          command: ./run_tests.sh

  composer-deploy:
    docker:
      - image: google/cloud-sdk
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
    environment:
      COMPOSER_BUCKET: gs://europe-west1-data-composer-0f2400f5-bucket/dags
      COMPOSER_ENV_NAME: data-composer
      COMPOSER_REGION: europe-west1
      DAG_RESTORE_DATA_ANALYTICS: restore_data_analytics_v1
      DAG_RECOMMMENDATION_CLOUDSQL: recommendation_cloud_sql_v6
    working_directory: ~/data-gcp/dags
    steps:
      - checkout:
          path: ~/data-gcp
      - run:
          name: Connect to GCP
          command: |
            echo $GCLOUD_SERVICE_KEY | gcloud auth activate-service-account --key-file=-
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
      - run:
          name: Deploy to composer
          command: |
            gsutil -m rsync -c -r . ${COMPOSER_BUCKET}
      - run:
          name: Wait for dags to be deployed
          command: |
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${COMPOSER_REGION} ${DAG_RECOMMMENDATION_CLOUDSQL} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${COMPOSER_REGION} ${DAG_RESTORE_DATA_ANALYTICS} 6 20
