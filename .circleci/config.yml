version: 2.1
orbs:
  cloudrun: circleci/gcp-cloud-run@1.0.2
  slack: circleci/slack@4.2

###################
#  SLACK
###################

slack-fail-post-step: &slack-fail-post-step
  post-steps:
    - slack/notify:
        event: fail
        channel: alertes_data
        branch_pattern: "^(master|production)"
        custom: |
          {
            "text": "",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "‚ùå *Echec* #${CIRCLE_BUILD_NUM} `${CIRCLE_PROJECT_REPONAME}` sur `${CIRCLE_BRANCH}`"
                }
              },
              {
                "type": "actions",
                "elements": [
                  {
                    "type": "button",
                    "text": {
                      "type": "plain_text",
                      "text": "View Job"
                    },
                    "url": "${CIRCLE_BUILD_URL}"
                  }
                ]
              }
            ]
          }



###################
#  Aliases
###################

deploy_on_dev_commons: &deploy_on_dev_commons
  filters:
    branches:
      only:
        - production
  context:
    - DATA_GCP
    - DATA_GCP_DEV
    - Slack
  <<: *slack-fail-post-step


###################
#  WORKFLOWS
###################

workflows:
  version: 2
  run-checks:
    jobs:

      - linter

      - analytics_tests:
          requires:
            - linter
          context:
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

# Recommendation jobs
# -------------------

      - recommendation-db-install:
          requires:
            - linter
          context:
            - Slack
          <<: *slack-fail-post-step

      - recommendation-db-tests:
          requires:
            - recommendation-db-install
          context:
            - Slack
          <<: *slack-fail-post-step

      - recommendation-api-build:
          requires:
            - linter
          context:
            - Slack
          <<: *slack-fail-post-step

      - recommendation-api-tests:
          requires:
            - recommendation-api-build
          context:
            - Slack
          <<: *slack-fail-post-step

      - api_integration_tests:
          env: dev
          api_token: $API_TOKEN_DEV
          name: recommendation-integration-tests-dev
          requires:
            - recommendation-api-tests
          context:
            - DATA_GCP_DEV
            - Slack
          <<: *slack-fail-post-step

      - build_and_deploy_api:
          name: build_and_deploy_api_staging
          api-instance-name : apireco-stg
          requires:
            - recommendation-api-tests
            - recommendation-db-tests
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - api_integration_tests:
          name: api_integration_tests_staging
          env: staging
          api_token: $API_TOKEN_STG
          requires:
            - build_and_deploy_api_staging
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - build_and_deploy_api:
          name: build_and_deploy_api_production
          api-instance-name : apireco-prod
          requires:
            - recommendation-api-tests
            - recommendation-db-tests
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step

      - api_integration_tests:
          name: api_integration_tests_production
          env: production
          api_token: $API_TOKEN_PROD
          requires:
            - build_and_deploy_api_production
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step

# Composer jobs
# -------------
      - orchestration-install:
          requires:
            - linter
          context:
            - Slack
          <<: *slack-fail-post-step

      - orchestration-tests:
          requires:
            - orchestration-install
          context:
            - Slack
          <<: *slack-fail-post-step

      - composer-deploy:
          name: staging-composer-deploy
          requires:
            - orchestration-tests
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - composer-deploy:
          name: production-composer-deploy
          requires:
            - orchestration-tests
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step



# Cloud Function jobs
# -------------------
      - cloud-function-deploy:
          name: typeform-cloud-function-deploy-stg
          cloud-function-name: qpi_import_stg
          cloud-function-folder: qpi-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: typeform-cloud-function-deploy-prod
          cloud-function-name: qpi_import_prod
          cloud-function-folder: qpi-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: addresses-cloud-function-deploy-stg
          cloud-function-name: addresses_import_stg
          cloud-function-folder: addresses-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: addresses-cloud-function-deploy-prod
          cloud-function-name: addresses_import_prod
          cloud-function-folder: addresses-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: downloads-cloud-function-deploy-stg
          cloud-function-name: downloads_stg
          cloud-function-folder: downloads-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: downloads-cloud-function-deploy-prod
          cloud-function-name: downloads_prod
          cloud-function-folder: downloads-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: typeform-webhook-cloud-function-deploy-stg
          cloud-function-name: qpi_webhook_stg
          cloud-function-folder: qpi-webhook-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - master
          context:
            - DATA_GCP
            - DATA_GCP_EHP
            - Slack
          <<: *slack-fail-post-step

      - cloud-function-deploy:
          name: typeform-webhook-cloud-function-deploy-prod
          cloud-function-name: qpi_webhook_prod
          cloud-function-folder: qpi-webhook-function-source
          requires:
            - linter
          filters:
            branches:
              only:
                - production
          context:
            - DATA_GCP
            - DATA_GCP_PROD
            - Slack
          <<: *slack-fail-post-step

# Slack alerts jobs
# ----------------
      - slack-alert:
          name: slack-alert-production
          destination_env: Production
          context: Slack
          filters:
            branches:
              only:
                - production
          requires:
            - analytics_tests
            - production-composer-deploy
            - api_integration_tests_production
            - recommendation-integration-tests-dev
            - typeform-cloud-function-deploy-prod
            - addresses-cloud-function-deploy-prod
            - typeform-webhook-cloud-function-deploy-prod

      - slack-alert:
          name: slack-alert-staging
          destination_env: Staging
          context: Slack
          filters:
            branches:
              only:
                - master
          requires:
            - analytics_tests
            - staging-composer-deploy
            - api_integration_tests_staging
            - recommendation-integration-tests-dev
            - typeform-cloud-function-deploy-stg
            - addresses-cloud-function-deploy-stg
            - typeform-webhook-cloud-function-deploy-stg

# ----------------
# Workflow to deploy on dev
# ----------------

  deploy_on_dev:
    jobs:
      - composer-deploy:
          name: dev-composer-deploy
          <<: *deploy_on_dev_commons
      - cloud-function-deploy:
          name: typeform-cloud-function-deploy-dev
          cloud-function-name: qpi_import_dev
          cloud-function-folder: qpi-function-source
          <<: *deploy_on_dev_commons
      - cloud-function-deploy:
          name: addresses-cloud-function-deploy-dev
          cloud-function-name: addresses_import_dev
          cloud-function-folder: addresses-function-source
          <<: *deploy_on_dev_commons
      - cloud-function-deploy:
          name: typeform-webhook-cloud-function-deploy-dev
          cloud-function-name: qpi_webhook_dev
          cloud-function-folder: qpi-webhook-function-source
          <<: *deploy_on_dev_commons
      - build_and_deploy_api:
          name: build_and_deploy_api_dev
          api-instance-name : apireco-dev
          <<: *deploy_on_dev_commons
      - api_integration_tests:
          env: dev
          api_token: $API_TOKEN_DEV
          name: api-integration-tests-dev
          requires:
            - dev-composer-deploy
            - typeform-cloud-function-deploy-dev
            - addresses-cloud-function-deploy-dev
            - build_and_deploy_api_dev
          context:
            - DATA_GCP_DEV
            - Slack
          <<: *slack-fail-post-step
      - slack-alert:
          name: slack-alert-dev
          destination_env: dev
          context: Slack
          requires:
            - api-integration-tests-dev



###################
#  EXECUTORS
###################

executors:
  python:
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
  gcp-sdk:
    docker:
      - image: google/cloud-sdk:316.0.0
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD

###################
#  JOBS
###################

jobs:
  linter:
    executor: python
    working_directory: ~/data-gcp
    steps:
      - checkout
      - restore_cache:
          key: deps-{{ checksum "linter-requirements.txt" }}
      - run:
          name: Install black
          command: |
            python3 -m venv venv-lint
            . venv-lint/bin/activate
            pip install -r linter-requirements.txt
      - save_cache:
          key: deps-{{ checksum "linter-requirements.txt" }}
          paths:
            - "venv-lint"
      - run:
          name: Run linter
          command: |
            . venv-lint/bin/activate
            black --exclude="venv-lint" --check .


  analytics_tests:
    executor: python
    working_directory: ~/data-gcp/analytics
    steps:
      - checkout:
          path: ~/data-gcp
      - restore_cache:
          key: deps-v2-{{ checksum "analytics-requirements.txt" }}
      - run:
          name: Install python dependencies
          command: |
            python3 -m venv venv-analytics
            . venv-analytics/bin/activate
            pip install -r analytics-requirements.txt
      - save_cache:
          key: deps-v2-{{ checksum "analytics-requirements.txt" }}
          paths:
            - "venv-analytics"
      - run:
          name: GCP service account authentication
          command: |
            echo $GCLOUD_SERVICE_KEY >> ~/data-gcp/analytics/gcloud_credentials.json
            echo GOOGLE_APPLICATION_CREDENTIALS=~/data-gcp/analytics/gcloud_credentials.json >> ~/data-gcp/.env
      - run:
          name: Run tests
          command: |
            . venv-analytics/bin/activate
            export PYTHONPATH=$PYTHONPATH:~/data-gcp:~/data-gcp/orchestration/dags
            pytest tests


  recommendation-api-build:
    executor: python
    working_directory: ~/data-gcp/recommendation/api
    steps:
      - checkout:
          path: ~/data-gcp
      - restore_cache:
          key: deps-{{ checksum "api-dev-requirements.txt" }}
      - run:
          name: Install Python deps in a venv
          command: |
            python3 -m venv venv-api
            . venv-api/bin/activate
            pip install -r api-dev-requirements.txt
      - save_cache:
          key: deps-{{ checksum "api-dev-requirements.txt" }}
          paths:
            - "venv-api"
      - persist_to_workspace:
          root: .
          paths:
            - .


  recommendation-api-tests:
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
      - image: kartoza/postgis:12.4
        environment:
          POSTGRES_PASS: postgres
          POSTGRES_USER: postgres
          POSTGRES_DBNAME: db
    working_directory: ~/data-gcp/recommendation/api
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install psql
          command: sudo apt install postgresql-client
      - run:
          name: Run tests
          command: |
            export PYTHONPATH=$PYTHONPATH:~/data-gcp/recommendation/api
            . venv-api/bin/activate
            ./run_tests.sh


  api_integration_tests:
    parameters:
      env:
        description: "Which environement to target"
        default: "dev"
        type: string
      api_token:
        description: "The api token (given with env var)"
        default: ""
        type: string
    docker:
      - image: postman/newman
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
    working_directory: ~/data-gcp
    steps:
      - run:
          name: Install Git
          command: |
            apk update
            apk upgrade
            apk add --no-cache bash git openssh
      - checkout
      - run:
          name: Run tests collection
          command: |
            cd recommendation/api/postman
            newman run api_integration_tests.postman_collection.json --environment <<parameters.env>>.postman_environment.json --env-var "api_token=<<parameters.api_token>>"


  orchestration-install:
    executor: python
    working_directory: ~/data-gcp/orchestration
    steps:
      - checkout:
          path: ~/data-gcp
      - restore_cache:
          key: deps-{{ checksum "orchestration-requirements.txt" }}
      - run:
          name: Install Python requirements
          command: |
            python3 -m venv venv-orchestration
            . venv-orchestration/bin/activate
            pip install -r orchestration-requirements.txt
      - save_cache:
          key: deps-{{ checksum "orchestration-requirements.txt" }}
          paths:
            - "venv-orchestration"
      - persist_to_workspace:
          root: .
          paths:
            - .


  orchestration-tests:
    executor: python
    working_directory: ~/data-gcp/orchestration
    environment:
        AIRFLOW_HOME: ~/data-gcp/orchestration
        DAG_FOLDER: ~/data-gcp/orchestration/dags
        RECOMMENDATION_SQL_INSTANCE: cloudsql-recommendation-circleci
        RECOMMENDATION_SQL_BASE: cloudsql-recommendation-circleci
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Run tests
          command: |
            . venv-orchestration/bin/activate
            airflow initdb
            pytest tests


  recommendation-db-install:
    executor: python
    working_directory: ~/data-gcp/recommendation/db
    steps:
      - checkout:
          path: ~/data-gcp
      - restore_cache:
          key: dependencies-{{ checksum "db-requirements.txt" }}
      - run:
          name: Install Python deps in a venv
          command: |
            python3 -m venv venv-db
            . venv-db/bin/activate
            pip install -r db-requirements.txt
      - save_cache:
          key: dependencies-{{ checksum "db-requirements.txt" }}
          paths:
            - "venv-db"
      - persist_to_workspace:
          root: .
          paths:
            - .


  recommendation-db-tests:
    docker:
      - image: circleci/python:3.7
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
      - image: circleci/postgres:12
        environment:
          POSTGRES_PASSWORD: postgres
    working_directory: ~/data-gcp/recommendation/db
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install psql
          command: sudo apt install postgresql-client
      - run:
          name: Run tests
          command: |
            export PYTHONPATH=$PYTHONPATH:~/data-gcp/recommendation/db
            . venv-db/bin/activate
            ./run_tests.sh


  composer-deploy:
    executor: gcp-sdk
    environment:
      DAG_RECOMMMENDATION_CLOUDSQL: recommendation_cloud_sql_v1
      DAG_EXPORT_CLOUDSQL_BIGQUERY: export_cloudsql_tables_to_bigquery_v1
      DAG_REFRESH_MATOMO_DATA: import_matomo_refresh_v1
      DAG_IMPORT_DATA_ANALYTICS: import_data_analytics_v6
      DAG_DUMP_SCALINGO_MATOMO_HISTORY: import_matomo_history_v1
      DAG_IMPORT_FIREBASE_DATA: import_firebase_data_v3
      DAG_IMPORT_TYPEFORM: import_typeform_v1
      DAG_IMPORT_ADDRESSES: import_addresses_v1
      DAG_IMPORT_DMS: import_dms_subscriptions
      DAG_COMPUTE_MONITORING: compute_monitoring
    working_directory: ~/data-gcp/orchestration
    steps:
      - checkout:
          path: ~/data-gcp
      - run:
          name: Connect to GCP
          command: |
            echo $GCLOUD_SERVICE_KEY | gcloud auth activate-service-account --key-file=-
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
      - run:
          name: Deploy to composer
          command: |
            gsutil -m rm -r gs://${COMPOSER_BUCKET}/dags
            gsutil cp -r dags gs://${COMPOSER_BUCKET}
      - run:
          name: Wait for dags to be deployed
          command: |
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_RECOMMMENDATION_CLOUDSQL} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_EXPORT_CLOUDSQL_BIGQUERY} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_REFRESH_MATOMO_DATA} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_IMPORT_DATA_ANALYTICS} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_DUMP_SCALINGO_MATOMO_HISTORY} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_IMPORT_FIREBASE_DATA} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_IMPORT_TYPEFORM} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_IMPORT_ADDRESSES} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_IMPORT_DMS} 6 20
            ./wait_for_dag_deployed.sh ${COMPOSER_ENV_NAME} ${REGION} ${DAG_COMPUTE_MONITORING} 6 20


  build_and_deploy_api:
    docker:
      - image: 'cimg/base:stable'
    parameters:
      api-instance-name:
        description: "API instance name"
        type: string
    working_directory: ~/data-gcp/recommendation/api
    steps:
      - checkout:
          path: ~/data-gcp
      - cloudrun/init
      - cloudrun/build:
          tag: 'eu.gcr.io/${GOOGLE_PROJECT_ID}/${CIRCLE_PROJECT_REPONAME}/<< parameters.api-instance-name >>:${CIRCLE_SHA1}'
      - run:
          name: Apply latest tag
          command: |
            gcloud container images add-tag \
            eu.gcr.io/${GOOGLE_PROJECT_ID}/${CIRCLE_PROJECT_REPONAME}/<< parameters.api-instance-name >>:${CIRCLE_SHA1} \
            eu.gcr.io/${GOOGLE_PROJECT_ID}/${CIRCLE_PROJECT_REPONAME}/<< parameters.api-instance-name >>:latest
      - cloudrun/deploy:
          image: 'eu.gcr.io/${GOOGLE_PROJECT_ID}/${CIRCLE_PROJECT_REPONAME}/<< parameters.api-instance-name >>:${CIRCLE_SHA1}'
          platform: managed
          region: europe-west1
          service-name: << parameters.api-instance-name >>
          unauthenticated: true


  slack-alert:
    docker:
      - image: cimg/base:stable
    parameters:
      destination_env:
        description: "The environnement on which we deploy."
        type: string
    steps:
      - run:
          name: Success
          when: always
          command: |
            exit 0
      - slack/notify:
          event: pass
          channel: alertes_data
          custom: |
            {
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "Le d√©ploiement sur *<<parameters.destination_env>>* est un succ√®s :rocket:"
                  }
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View job",
                        "emoji": true
                      },
                      "url": "$CIRCLE_BUILD_URL"
                    }
                  ]
                },
                {
                  "type": "context",
                  "elements": [
                    {
                      "type": "plain_text",
                      "text": "Author: $CIRCLE_USERNAME",
                      "emoji": true
                    }
                  ]
                }
              ]
            }

  cloud-function-deploy:
    executor: gcp-sdk
    parameters:
      cloud-function-name:
        description: "The cloud function name"
        type: string
      cloud-function-folder:
        description: "The cloud function code folder"
        type: string
    working_directory: ~/data-gcp
    steps:
      - checkout:
          path: ~/data-gcp
      - run:
          name: Connect to GCP
          command: |
            echo $GCLOUD_SERVICE_KEY | gcloud auth activate-service-account --key-file=-
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
      - run:
          name: Deploy the function
          command: |
            cd additional_data_sources/<<parameters.cloud-function-folder>>
            gcloud functions deploy << parameters.cloud-function-name >> --region "europe-west1"  --entry-point run --source .
