{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from models.v2.two_towers.two_towers_match_model import TwoTowersMatchModel\n",
    "from models.v2.two_towers.two_towers_model import TwoTowersModel\n",
    "from models.v1.utils import identity_loss\n",
    "from models.v2.utils import load_triplets_dataset\n",
    "from utils import ENV_SHORT_NAME\n",
    "\n",
    "\n",
    "N_EPOCHS = 1000\n",
    "VERBOSE = 0 if ENV_SHORT_NAME == \"prod\" else 1\n",
    "LOSS_CUTOFF = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_layer_infos = {\n",
    "    \"user_id\": {\"type\": \"string\", \"feature_latent_dim\": 128},\n",
    "    \"user_age\": {\"type\": \"int\", \"feature_latent_dim\": 16},\n",
    "    \"user_postal_code\": {\"type\": \"string\", \"feature_latent_dim\": 8},\n",
    "    \"user_activity\": {\"type\": \"string\", \"feature_latent_dim\": 8},\n",
    "    \"user_booking_cnt\": {\"type\": \"int\", \"feature_latent_dim\": 16},\n",
    "    \"user_theoretical_amount_spent\": {\"type\": \"int\", \"feature_latent_dim\": 16},\n",
    "    \"user_theoretical_remaining_credit\": {\"type\": \"int\", \"feature_latent_dim\": 16},\n",
    "    \"user_distinct_type_booking_cnt\": {\"type\": \"int\", \"feature_latent_dim\": 16},\n",
    "}\n",
    "item_layer_infos = {\n",
    "    \"item_id\": {\"type\": \"string\", \"feature_latent_dim\": 128},\n",
    "    \"offer_categoryId\": {\"type\": \"string\", \"feature_latent_dim\": 16},\n",
    "    \"offer_subcategoryid\": {\"type\": \"string\", \"feature_latent_dim\": 16},\n",
    "    \"item_names\": {\"type\": \"text\", \"feature_latent_dim\": 16},\n",
    "    \"item_rayons\": {\"type\": \"text\", \"feature_latent_dim\": 16},\n",
    "    \"item_author\": {\"type\": \"text\", \"feature_latent_dim\": 16},\n",
    "    \"item_performer\": {\"type\": \"text\", \"feature_latent_dim\": 16},\n",
    "    \"item_mean_stock_price\": {\"type\": \"int\", \"feature_latent_dim\": 8},\n",
    "    \"item_booking_cnt\": {\"type\": \"int\", \"feature_latent_dim\": 8},\n",
    "    \"item_favourite_cnt\": {\"type\": \"int\", \"feature_latent_dim\": 8},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "STORAGE_PATH = \"gs://mlflow-bucket-ehp/algo_training_stg/algo_training_v2_two_tower_20230111T094741\"\n",
    "\n",
    "# Load BigQuery data\n",
    "train_data = pd.read_csv(f\"{STORAGE_PATH}/positive_data_train.csv\").astype(str)\n",
    "validation_data = pd.read_csv(f\"{STORAGE_PATH}/positive_data_eval.csv\").astype(str)\n",
    "\n",
    "user_columns = list(user_layer_infos.keys())\n",
    "item_columns = list(item_layer_infos.keys())\n",
    "\n",
    "user_data = train_data[user_columns].drop_duplicates(subset=[\"user_id\"])\n",
    "item_data = train_data[item_columns].drop_duplicates(subset=[\"item_id\"])\n",
    "\n",
    "# Create tf datasets\n",
    "train_dataset = load_triplets_dataset(\n",
    "    train_data, user_columns=user_columns, item_columns=item_columns, batch_size=batch_size\n",
    ")\n",
    "validation_dataset = load_triplets_dataset(\n",
    "    validation_data, user_columns=user_columns, item_columns=item_columns, batch_size=batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "\n",
    "two_tower_model = TwoTowersModel(\n",
    "    user_data=user_data,\n",
    "    user_layer_infos=user_layer_infos,\n",
    "    item_data=item_data,\n",
    "    item_layer_infos=item_layer_infos,\n",
    "    embedding_size=embedding_size,\n",
    ")\n",
    "\n",
    "two_tower_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "\n",
    "two_tower_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_data=validation_dataset,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            min_delta=LOSS_CUTOFF,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=3,\n",
    "            min_delta=LOSS_CUTOFF,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_embeddings = two_tower_model.user_model([user_data.values])\n",
    "item_embeddings = two_tower_model.item_model([item_data.values])\n",
    "\n",
    "match_model_last_layer = TwoTowersMatchModel(\n",
    "    user_ids=user_data[\"user_id\"].unique(),\n",
    "    user_embeddings=user_embeddings,\n",
    "    item_ids=item_data[\"item_id\"].unique(),\n",
    "    item_embeddings=item_embeddings,\n",
    "    embedding_size=embedding_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "match_model_first_layer = TwoTowersMatchModel(\n",
    "    user_ids=two_tower_model.user_model.layers[0].layers[0].get_vocabulary()[1:],\n",
    "    user_embeddings=two_tower_model.user_model.layers[0].layers[1].get_weights()[0][1:],\n",
    "    item_ids=two_tower_model.item_model.layers[0].layers[0].get_vocabulary()[1:],\n",
    "    item_embeddings=two_tower_model.item_model.layers[0].layers[1].get_weights()[0][1:],\n",
    "    embedding_size=embedding_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA Plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "colormap = mpl.colormaps[\"tab20\"].colors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "item_ids = match_model_first_layer.item_layer.layers[0].get_vocabulary()[1:]\n",
    "embeddings = match_model_first_layer.item_layer.layers[1].get_weights()[0][1:]\n",
    "\n",
    "pca_out = PCA(n_components=2).fit_transform(embeddings)\n",
    "categories = item_data[\"offer_categoryId\"].unique().tolist()\n",
    "item_representation = pd.DataFrame(\n",
    "    {\n",
    "        \"item_id\": item_ids,\n",
    "        \"x\": pca_out[:, 0],\n",
    "        \"y\": pca_out[:, 1],\n",
    "    }\n",
    ").merge(train_data[item_columns].drop_duplicates(subset=[\"item_id\"]), on=[\"item_id\"], how=\"inner\")\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    data = item_representation.loc[lambda df: df[\"offer_categoryId\"] == category]\n",
    "    ax.scatter(\n",
    "        data[\"x\"].values,\n",
    "        data[\"y\"].values,\n",
    "        s=10,\n",
    "        color=colormap[idx],\n",
    "        label=category,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    RECOMMENDATION_NUMBER,\n",
    "    NUMBER_OF_PRESELECTED_OFFERS,\n",
    "    EVALUATION_USER_NUMBER,\n",
    ")\n",
    "from metrics import compute_metrics, get_actual_and_predicted\n",
    "\n",
    "positive_data_test = pd.read_csv(\n",
    "        f\"{STORAGE_PATH}/positive_data_test.csv\",\n",
    "        dtype={\n",
    "            \"user_id\": str,\n",
    "            \"item_id\": str,\n",
    "        },\n",
    "    ).assign(genres=\"\").assign(type=\"\").assign(rayon=\"\")\n",
    "\n",
    "users_to_test = positive_data_test[\"user_id\"].unique()[\n",
    "    : min(EVALUATION_USER_NUMBER, positive_data_test[\"user_id\"].nunique())\n",
    "]\n",
    "positive_data_test = positive_data_test.loc[\n",
    "    lambda df: df[\"user_id\"].isin(users_to_test)\n",
    "]\n",
    "\n",
    "data_model_dict = {\n",
    "    \"data\": {\n",
    "        \"raw\": train_data.assign(genres=\"\").assign(type=\"\").assign(rayon=\"\"),\n",
    "        \"training_item_ids\": train_data.item_id.unique(),\n",
    "        \"test\": positive_data_test,\n",
    "    },\n",
    "    \"model\": match_model,\n",
    "}\n",
    "data_model_dict_w_actual_and_predicted = get_actual_and_predicted(data_model_dict)\n",
    "\n",
    "metrics = {}\n",
    "k_list = [RECOMMENDATION_NUMBER, NUMBER_OF_PRESELECTED_OFFERS]\n",
    "for k in k_list:\n",
    "    data_model_dict_w_metrics_at_k = compute_metrics(\n",
    "        data_model_dict_w_actual_and_predicted, k\n",
    "    )\n",
    "\n",
    "    metrics[f\"recall_at_{k}\"] = data_model_dict_w_metrics_at_k[\"metrics\"][\"mark\"]\n",
    "    metrics[f\"precision_at_{k}\"] = data_model_dict_w_metrics_at_k[\"metrics\"][\"mapk\"]\n",
    "\n",
    "    # Here we track metrics relate to pcreco output\n",
    "    if k == RECOMMENDATION_NUMBER:\n",
    "\n",
    "        metrics[f\"recall_at_{k}_panachage\"] = data_model_dict_w_metrics_at_k[\n",
    "            \"metrics\"\n",
    "        ][\"mark_panachage\"]\n",
    "        metrics[f\"precision_at_{k}_panachage\"] = data_model_dict_w_metrics_at_k[\n",
    "            \"metrics\"\n",
    "        ][\"mapk_panachage\"]\n",
    "\n",
    "        # AVG diverisification score is only calculate at k=RECOMMENDATION_NUMBER to match pcreco output\n",
    "        metrics[\n",
    "            f\"avg_diversification_score_at_{k}\"\n",
    "        ] = data_model_dict_w_metrics_at_k[\"metrics\"][\"avg_div_score\"]\n",
    "\n",
    "        metrics[\n",
    "            f\"avg_diversification_score_at_{k}_panachage\"\n",
    "        ] = data_model_dict_w_metrics_at_k[\"metrics\"][\"avg_div_score_panachage\"]\n",
    "\n",
    "        metrics[\n",
    "            f\"personalization_at_{k}_panachage\"\n",
    "        ] = data_model_dict_w_metrics_at_k[\"metrics\"][\n",
    "            \"personalization_at_k_panachage\"\n",
    "        ]\n",
    "\n",
    "    metrics[f\"coverage_at_{k}\"] = data_model_dict_w_metrics_at_k[\"metrics\"][\n",
    "        \"coverage\"\n",
    "    ]\n",
    "\n",
    "    metrics[f\"personalization_at_{k}\"] = data_model_dict_w_metrics_at_k[\"metrics\"][\n",
    "        \"personalization_at_k\"\n",
    "    ]\n",
    "\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}