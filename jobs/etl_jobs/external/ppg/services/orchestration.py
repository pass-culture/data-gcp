from typing import Any, Dict, List, Optional

from duckdb import DuckDBPyConnection

from config import (
    AGG_TYPE_MAPPING,
    DEFAULT_AGG_TYPE,
    SHEET_DEFINITIONS,
    SHEET_LAYOUT,
    SOURCE_TABLES,
)
from services.data import DataService
from services.excel_layout import ExcelLayoutService
from services.excel_writer import ExcelWriterService
from services.tracking import KPIResult, KPIStatus, SheetStats, TopResult, TopStatus
from utils.verbose_logger import log_print


class ReportOrchestrationService:
    """Orchestrates the complete report generation process with error handling."""

    def __init__(self, duckdb_conn: DuckDBPyConnection):
        self.conn = duckdb_conn
        self.data_service = DataService(duckdb_conn)

    def _get_layout_type(self, sheet) -> str:
        """Determine layout type based on sheet definition."""
        if sheet.definition.startswith("top"):
            return "top"
        elif sheet.definition.endswith("kpis"):
            return "kpis"
        else:
            return "other"

    def process_all_sheets(self, sheets: List, ds: str) -> List[SheetStats]:
        """
        Process all sheets in a report with comprehensive error handling.

        Args:
            sheets: List of Sheet objects from Report
            ds: Consolidation date in YYYY-MM-DD format

        Returns:
            List of SheetStats with detailed results
        """
        all_sheet_stats = []

        log_print.info(f"➡️  Processing {len(sheets)} sheets")

        for sheet in sheets:
            try:
                sheet_stats = self._process_single_sheet(sheet, ds)
                all_sheet_stats.append(sheet_stats)

            except Exception as e:
                log_print.warning(
                    f"Unexpected error processing sheet {sheet.tab_name}: {e}"
                )
                # Create failed sheet stats
                sheet_stats = SheetStats(
                    sheet_name=sheet.tab_name, sheet_type=sheet.definition
                )
                all_sheet_stats.append(sheet_stats)

        # Summary logging
        total_sheets = len(all_sheet_stats)
        successful_sheets = sum(
            1
            for s in all_sheet_stats
            if (
                s.kpis_successful > 0
                or s.tops_successful > 0
                or (len(s.kpi_results) == 0 and len(s.top_results) == 0)
            )
        )

        log_print.info(
            f"✅ Processing complete: {successful_sheets}/{total_sheets} sheets successful"
        )

        return all_sheet_stats

    def _process_single_sheet(self, sheet, ds: str) -> SheetStats:
        """
        Process a single sheet with error recovery.

        Args:
            sheet: Sheet object with worksheet, definition, context, filters
            ds: Consolidation date

        Returns:
            SheetStats with detailed results
        """
        sheet_stats = SheetStats(sheet_name=sheet.tab_name, sheet_type=sheet.definition)

        try:
            log_print.debug(f"📊 Processing sheet: {sheet.tab_name}")

            # Step 1: Layout preprocessing (date column expansion)
            expansion_result = self._handle_layout_preprocessing(sheet, ds)
            if not expansion_result and sheet.definition.endswith("kpis"):
                log_print.warning(f"Failed to expand date columns for {sheet.tab_name}")
                return sheet_stats

            # Extract date_mappings from expansion_result
            date_mappings = (
                expansion_result.get("date_mappings") if expansion_result else {}
            )

            # Step 2: Fill data based on sheet type
            if sheet.definition in ("individual_kpis", "collective_kpis"):
                self._handle_kpi_data_filling(sheet, ds, date_mappings, sheet_stats)
            elif sheet.definition.startswith("top"):
                self._handle_top_data_filling(sheet, ds, sheet_stats)
            elif sheet.definition == "lexique":
                # Lexique sheets need no data processing
                pass
            else:
                log_print.warning(f"Unknown sheet definition: {sheet.definition}")

            # Log completion
            if sheet.definition in ("individual_kpis", "collective_kpis"):
                log_print.debug(
                    f"✅ Completed sheet {sheet.tab_name}: "
                    f"{sheet_stats.kpis_successful} KPIs successful, "
                    f"{sheet_stats.kpis_failed} KPIs failed, "
                    f"{sheet_stats.kpis_no_data} KPIs with no data"
                )
            elif sheet.definition.startswith("top"):
                log_print.debug(
                    f"✅ Completed sheet {sheet.tab_name}: "
                    f"{sheet_stats.tops_successful} tops successful, "
                    f"{sheet_stats.tops_failed} tops failed"
                )
            elif sheet.definition == "lexique":
                log_print.debug(f"✅ Completed sheet {sheet.tab_name}")

            # Step 3: Delete template columns and Set title
            layout_type = self._get_layout_type(sheet)
            ExcelLayoutService.cleanup_template_columns(sheet.worksheet, layout_type)
            self._handle_title_setting(sheet, expansion_result)
            ExcelLayoutService.freeze_panes(sheet.worksheet, layout_type)

            return sheet_stats

        except Exception as e:
            log_print.warning(f"Failed to process sheet {sheet.tab_name}: {e}")
            return sheet_stats

    def _handle_layout_preprocessing(self, sheet, ds: str) -> Optional[Dict[str, Any]]:
        """Handle Excel layout preprocessing (date column expansion)."""
        try:
            if sheet.definition.endswith("kpis"):
                expansion_result = ExcelLayoutService.expand_date_columns_kpis(
                    worksheet=sheet.worksheet, sheet_definition=sheet.definition, ds=ds
                )
                return expansion_result
            return {}  # No date mappings needed for non-KPI sheets

        except Exception as e:
            log_print.warning(f"Layout preprocessing failed for {sheet.tab_name}: {e}")
            return None

    def _handle_title_setting(self, sheet, expansion_result: Dict[str, Any] = None):
        """Handle sheet title setting."""
        try:
            # Determine layout type
            layout_type = self._get_layout_type(sheet)

            expanded_width = None
            if layout_type == "kpis" and expansion_result:
                expanded_width = expansion_result.get("total_width")
            ExcelLayoutService.set_sheet_title(
                worksheet=sheet.worksheet,
                title_base=sheet.tab_name or sheet.definition.capitalize(),
                layout_type=layout_type,
                context=sheet.context or {},
                filters=sheet.filters or {},
                expanded_width=expanded_width,
                sheet_definition=sheet.definition,
            )

        except Exception as e:
            log_print.warning(f"Failed to set title for {sheet.tab_name}: {e}")

    def _handle_top_data_filling(self, sheet, ds: str, sheet_stats: SheetStats):
        """Handle top data filling for top sheets."""
        try:
            source_table_key = SHEET_DEFINITIONS[sheet.definition].get("source_table")
            if not source_table_key or source_table_key not in SOURCE_TABLES:
                log_print.warning(
                    f"No source table found for sheet definition: {sheet.definition}"
                )
                top_result = TopResult(
                    top_name=sheet.definition,
                    status=TopStatus.FAILED,
                    error_message="No source table configured",
                )
                sheet_stats.add_top_result(top_result)
                return

            table_config = SOURCE_TABLES[source_table_key]
            table_name = table_config["table"]

            dimension_context = sheet.get_dimension_context()
            if not dimension_context:
                log_print.warning(
                    f"Could not resolve dimension context for {sheet.tab_name}"
                )
                top_result = TopResult(
                    top_name=sheet.definition,
                    status=TopStatus.FAILED,
                    error_message="Could not resolve dimension context",
                )
                sheet_stats.add_top_result(top_result)
                return

            min_row = (
                SHEET_LAYOUT["top"]["title_row_offset"]
                + SHEET_LAYOUT["top"]["title_height"]
                + 2
            )

            top_data = self.data_service.get_top_rankings(
                dimension_name=dimension_context["name"],
                dimension_value=dimension_context["value"],
                ds=ds,
                table_name=table_name,
                top_n=SHEET_DEFINITIONS[sheet.definition].get("top_n", 50),
                select_fields=SHEET_DEFINITIONS[sheet.definition].get(
                    "select_fields", []
                ),
                order_by=SHEET_DEFINITIONS[sheet.definition].get("order_by", []),
            )

            if top_data is not None and len(top_data) > 0:
                # Write data to Excel
                write_success = ExcelWriterService.write_top_data_to_sheet(
                    worksheet=sheet.worksheet, top_data=top_data, start_row=min_row
                )

                if write_success:
                    top_result = TopResult(
                        top_name=sheet.definition,
                        status=TopStatus.SUCCESS,
                        rows_written=len(top_data),
                    )
                else:
                    top_result = TopResult(
                        top_name=sheet.definition,
                        status=TopStatus.FAILED,
                        error_message="Failed to write data to Excel",
                    )
                sheet_stats.add_top_result(top_result)
            else:
                top_result = TopResult(
                    top_name=sheet.definition,
                    status=TopStatus.NO_DATA,
                    error_message="No data returned from query",
                )
                sheet_stats.add_top_result(top_result)

        except Exception as e:
            log_print.warning(f"Top data filling failed for {sheet.tab_name}: {e}")
            top_result = TopResult(
                top_name=sheet.definition, status=TopStatus.FAILED, error_message=str(e)
            )
            sheet_stats.add_top_result(top_result)

    def _handle_kpi_data_filling(
        self, sheet, ds: str, date_mappings: Dict[str, Any], sheet_stats: SheetStats
    ):
        """Handle KPI data filling for KPI sheets."""
        try:
            # Get data source table
            source_table_key = SHEET_DEFINITIONS[sheet.definition].get("source_table")
            if not source_table_key or source_table_key not in SOURCE_TABLES:
                log_print.warning(
                    f"No source table found for sheet definition: {sheet.definition}"
                )
                return

            table_config = SOURCE_TABLES[source_table_key]
            table_name = table_config["table"]
            scope = (
                "individual" if sheet.definition == "individual_kpis" else "collective"
            )

            # Get dimension context
            dimension_context = sheet.get_dimension_context()
            if not dimension_context:
                log_print.warning(
                    f"Could not resolve dimension context for {sheet.tab_name}"
                )
                return

            # Process each KPI row
            min_row = (
                SHEET_LAYOUT["kpis"]["title_row_offset"]
                + SHEET_LAYOUT["kpis"]["title_height"]
                + 2
            )

            # Calculate total cells for tracking
            total_years = len(date_mappings.get("years", []))
            total_months = len(date_mappings.get("months", []))
            total_cells_per_kpi = total_years + total_months

            for row_idx, row in enumerate(
                sheet.worksheet.iter_rows(
                    min_row=min_row, max_row=sheet.worksheet.max_row
                )
            ):
                kpi_config = self._parse_kpi_row(row, row_idx + min_row - 1)
                if not kpi_config:
                    continue

                kpi_name = kpi_config["kpi_name"]

                # Get KPI data
                kpi_data = self.data_service.get_kpi_data(
                    kpi_name=kpi_name,
                    dimension_name=dimension_context["name"],
                    dimension_value=dimension_context["value"],
                    ds=ds,
                    scope=scope,
                    table_name=table_name,
                    select_field=kpi_config["select_field"],
                    agg_type=kpi_config["agg_type"],
                )

                if kpi_data:
                    # Write data to Excel
                    write_success = ExcelWriterService.write_kpi_data_to_sheet(
                        worksheet=sheet.worksheet,
                        kpi_data=kpi_data,
                        date_mappings=date_mappings,
                        row_idx=kpi_config["row_idx"],
                    )

                    if write_success:
                        # Count how many values were actually written
                        values_written = 0
                        yearly_data = kpi_data.get("yearly", {})
                        monthly_data = kpi_data.get("monthly", {})
                        values_written = len(yearly_data) + len(monthly_data)

                        kpi_result = KPIResult(
                            kpi_name=kpi_name,
                            status=KPIStatus.SUCCESS,
                            values_written=values_written,
                            total_cells=total_cells_per_kpi,
                        )
                    else:
                        kpi_result = KPIResult(
                            kpi_name=kpi_name,
                            status=KPIStatus.WRITE_FAILED,
                            values_written=0,
                            total_cells=total_cells_per_kpi,
                            error_message="Failed to write to Excel",
                        )
                        log_print.warning(
                            f"Failed to write KPI '{kpi_name}' to sheet {sheet.tab_name}"
                        )

                    sheet_stats.add_kpi_result(kpi_result)
                else:
                    kpi_result = KPIResult(
                        kpi_name=kpi_name,
                        status=KPIStatus.NO_DATA,
                        values_written=0,
                        total_cells=total_cells_per_kpi,
                        error_message="No data returned from query",
                    )
                    sheet_stats.add_kpi_result(kpi_result)
                    log_print.warning(
                        f"No data found for KPI '{kpi_name}' in sheet {sheet.tab_name}"
                    )

        except Exception as e:
            log_print.warning(f"KPI data filling failed for {sheet.tab_name}: {e}")

    def _parse_kpi_row(self, row, row_idx: int) -> Optional[Dict[str, Any]]:
        """
        Parse a KPI row configuration from Excel cells.

        Args:
            row: Excel row from openpyxl
            row_idx: Row index (0-based)

        Returns:
            KPI configuration dict or None if parsing failed
        """
        try:
            # Parse filter cell (expected format: "kpi_name=actual_name")
            filter_cell = row[0].value if len(row) > 0 else None
            if not filter_cell or "=" not in str(filter_cell):
                return None

            kpi_name = str(filter_cell).split("=")[1].strip()
            if not kpi_name:
                return None

            # Parse select field (default: kpi)
            select_field = "kpi"
            if len(row) > 1 and row[1].value:
                select_field = str(row[1].value).strip().lower()

            # Parse aggregation type (default: sum)
            excel_agg_type = DEFAULT_AGG_TYPE
            if len(row) > 2 and row[2].value:
                excel_agg_type = str(row[2].value).strip().lower()

            # Map Excel value to technical value
            mapped_agg_type = self._map_aggregation_type(excel_agg_type)

            return {
                "kpi_name": kpi_name,
                "select_field": select_field,
                "agg_type": mapped_agg_type,
                "row_idx": row_idx,
            }

        except Exception as e:
            log_print.debug(f"Failed to parse KPI row at index {row_idx}: {e}")
            return None

    def _map_aggregation_type(self, excel_agg_type: str) -> str:
        """Map Excel aggregation type to technical aggregation type."""
        if not excel_agg_type:
            return DEFAULT_AGG_TYPE

        # Clean the input (lowercase, strip spaces)
        clean_agg_type = excel_agg_type.lower().strip()

        # Look up in mapping
        LOWER_AGG_TYPE_MAPPING = {
            k.lower().strip(): v for k, v in AGG_TYPE_MAPPING.items()
        }
        technical_agg_type = LOWER_AGG_TYPE_MAPPING.get(
            clean_agg_type, DEFAULT_AGG_TYPE
        )
        if technical_agg_type != clean_agg_type:
            log_print.debug(
                f"Mapped aggregation type: '{excel_agg_type}' -> '{technical_agg_type}'"
            )

        return technical_agg_type
