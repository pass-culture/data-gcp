version: 2

macros:

  - name: render_case_when
    description: |
      Generates a SQL CASE WHEN statement based on a mapping list.
      Each mapping item must have a `name` (string or iterable of strings) and a `label`.
      Optionally, a fallback value can be provided as either `fallback_sql` or `fallback_str`, but not both.
    arguments:
      - name: input_column_name
        description: The column name to evaluate in the CASE WHEN statement.
        type: string
      - name: mapping_list
        description: |
          A list of mappings where each item has:
            - name: string or list of strings representing values to match
            - label: string representing the label to return when matched
        type: list
      - name: fallback_sql
        description: Optional SQL snippet to use as the ELSE clause.
        type: string
      - name: fallback_str
        description: Optional string to use as the ELSE clause.
        type: string

  - name: discovery_vars
    description: ""

  - name: extract_params_int_value
    description: |
      This macro generates a SQL snippet to extract the `int_value` from event parameters in a nested structure, based on the provided list of parameter keys.
      See extract_params_string_value for detailed explanation.

  - name: extract_params_string_value
    description: |
      This macro generates a SQL snippet to extract the `string_value` from event parameters in a nested structure, based on the provided list of parameter keys.

      Parameters
      - params: A list of parameter keys for which the corresponding `string_value` should be extracted from the event parameters.

      Example
      The call of extract_params_string_value(["param1", "param2" ]) generates the following SQL query:
      ```sql
      (SELECT event_params.value.string_value FROM UNNEST(event_params) event_params WHERE event_params.key = 'param1') AS param1,
      (SELECT event_params.value.string_value FROM UNNEST(event_params) event_params WHERE event_params.key = 'param2') AS param2
      ```

  - name: extract_str_to_array_field
    description: |
      This macro generates a SQL query to concatenate and process multiple string columns
      dynamically based on the specified start, step, and end values. The macro
      constructs column names such as `{column_name}_1_10`, `{column_name}_11_20`, etc., splits
      the comma-separated string values into arrays, and combines these arrays into
      a single array. It filters out null and empty strings from the final array.

      Parameters:
        - column_name (str): The name of the columns
        - start (int): The starting index for generating column names.
        - step (int): The step size to increment the index for generating column names.
        - end (int): The ending index (exclusive) for generating column names.

      Example:
        The call of extract_str_to_array_field(offers, 0, 10, 50) generates the following SQL query:
      ```sql
      ARRAY(
        SELECT _col
        FROM UNNEST(
          ARRAY_CONCAT(
            SPLIT(IFNULL(offers_1_10, ''), ','),
            SPLIT(IFNULL(offers_11_20, ''), ','),
            SPLIT(IFNULL(offers_21_30, ''), ','),
            SPLIT(IFNULL(offers_31_40, ''), ','),
            SPLIT(IFNULL(offers_41_50, ''), ',')
          )
        ) AS _col
        WHERE _col IS NOT NULL AND _col != ''
      )
      ```

  - name: generate_schema_name
    description: |
      Overview
      It enables us to set up the destination dataset.
      If we develop in local (target = local), the destination schema dataset is the default (tmp_env) specified in profile.yml.
      If the model is in intermediate folder, schema name = int_{sub_folder_name}_{target_name}
      Else the destination schema dataset is specified in dbt_project.yml (analytics_env or clean_env)
  - name: generate_seed_geolocation_query
    description: |
      Macro that is used in the specific context of `Ã¬ntermediate/geolocation` files. It is used to generate the SQL query that will calculate location metadata of France (ZRR, QPV, IRIS, EPCI).

      Parameters:
        source_table: The table that contains latitude / longitude couple. This can either be a source table (two elements) or a ref table within the current dbt project (with one element).
        referential_table: The table that contains geospatial reference data (e.g., geographical boundaries) against which the source data will be matched. Similar to source_table, it can be either a source or a reference.
        id_column: The column name(s) in the source_table that uniquely identify each record. Can be a string (e.g., "user_id", "venue_id") or a list for composite keys (e.g., ["user_id", "info_history_rank"]).
        prefix_name: A prefix used to identify the latitude and longitude columns in the source_table. For example <user> for user_latitude, user_longitude or <venue> For venue_latitude, venue_longitude).
        columns: A list of column names from the referential_table that you want to include in the final result.
        geo_shape (optional, default: 'geo_shape'): The name of the column in the referential_table that contains the geographical shapes (e.g., polygons) used for geospatial matching.

      Example:
        See the int_geo__user_location model in the `intermediate` folder.

  - name: generate_alias_name
    description: " This macro generates table aliases
    - By using the segment after '__' for models in the intermediate folder.
    - By removing 'mrt' and replacing '__' by '_' for models in the mart folder.
    - Otherwise, it uses the model's name.
    "

  - name: custom_incremental_config
    description: "materialize incremental models as views in CI"
